---
title: "Final Project"
author: "Xinyi Lin"
date: "5/10/2019"
output:
  pdf_document: default
  html_document: default
---


```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(truncnorm)
library(mvtnorm)
library(matrixcalc)
```


## Problem 1

### Question 1

First, we need to tidy data. As the day of year $x_{i,1}(t)$ and time $t$ are two variables in given model, we need to transform `time` into some suitable formats. Normally, records are taken every 6 hour at 00:00:00, 06:00:00, 12:00:00 and 18:00:00. However, some records are taken at other timepoints. These records are ineffective as there are no records 6 hour before or after those timepoints to help train or test given models. Thus, we remove those observations.

```{r}
shift <- function(x, n=1){
  c(x[-(seq(n))], rep(NA, n))
}
```

```{r}
data1 = read.csv("./hurrican356.csv") %>% 
  janitor::clean_names() %>% 
  mutate(year = season,
         date_hour = time) %>% 
  separate(date_hour, into = c("date", "hour"), sep = " ") %>% 
  filter(hour == "00:00:00)" | hour == "06:00:00)" | hour == "12:00:00)" | hour == "18:00:00)") %>% 
  mutate(hour = str_replace(hour, ":00:00\\)", ""),
         hour = as.numeric(hour),
         date = str_replace(date, "\\(", ""),
         date = yday(date),
         nature = as.numeric(as.factor(nature))) %>% 
  group_by(id) %>% 
  mutate(delta1 = c(NA, diff(latitude)),
         delta2 = c(NA, diff(longitude)),
         delta3 = c(NA, diff(wind_kt)),
         latitude_p = shift(latitude),
         longitude_p = shift(longitude),
         windkt_p = shift(wind_kt)) %>% 
  ungroup() %>% 
  na.omit() %>% 
  select(id, latitude, longitude, wind_kt, latitude_p, longitude_p, windkt_p, date, year, nature, delta1, delta2, delta3)

#head(data1)
#summary(data1)
```

Then, we randomely select 80% hurricanes.

```{r}
set.seed(123)
id = unique(data1$id)
num_id = length(id)
train_id = sample(id, 0.8*num_id)

train_data = data1[which(data1$id %in% train_id),] %>% 
  select(-id)
```

After that, we use M-H algorithm to develop an MCMC process.

As $$Y_{i,j}(t+6) = \mu_{i,j}(t) + \rho_jY_{i,j}(t) + \epsilon_{i,j}(t)$$

$$Y_i \sim MVN \bigg( \left[
 \begin{matrix}
   \mu_{i,1}(t)+\rho Y_{i,1}(t) \\
   \mu_{i,2}(t)+\rho Y_{i,2}(t) \\
   \mu_{i,3}(t)+\rho Y_{i,3}(t) \\
  \end{matrix}
  \right], \Sigma \bigg)$$ 

$$f_{Y_i(t+6)}(Y_i|\rho_j, \beta, \Sigma) = \frac{exp[-\frac{1}{2}(Y_i-\mu)^T\Sigma^{-1}(Y_i-\mu)]}{\sqrt{(2\pi)^k|\Sigma|}}$$

$$\pi(\theta) = \prod\frac{exp[-\frac{1}{2}(Y_i-\mu)^T\Sigma^{-1}(Y_i-\mu)]}{\sqrt{(2\pi)^k|\Sigma|}}\times\pi_1(\beta)\pi_2(\rho_1)\pi_3(\rho_2)\pi_4(\rho_3)\pi_5(\Sigma^{-1})$$

$$\pi'(\theta) = \sum log[\frac{exp[-\frac{1}{2}(Y_i-\mu)^T\Sigma^{-1}(Y_i-\mu)]}{\sqrt{(2\pi)^k|\Sigma|}}]+log[\pi_1(\beta)]+log[\pi_2(\rho_1)]+log[\pi_3(\rho_2)]+log[\pi_4(\rho_3)]+log[\pi_5(\Sigma^{-1})]$$

Let $\theta = (\beta,\rho_j,\Sigma)$, with probability

$$\alpha(\lambda|\theta^{(t)}) = min \left\{ 1,\frac{\pi'(\lambda)q(\theta^{(t)}|\lambda)}{\pi'(\theta^{(t)})q(\lambda|\theta^{(t)})}\right\}$$

Accept $\theta^{(t+1)} = \lambda$, else, set$\theta^{(t+1)} = \theta^{(t)}$.

Starting points.

```{r}
set.seed(111)
# rho: 1*3 vector
#rho = rtruncnorm(3, a=0, b=1, mean = 0.5, sd = 1/5)
rho = rep(0.8, 3)
# epsilon: 1*3 vector
sigma = bayesm::rwishart(3,diag(0.1,3))$IW
sigma = c(sigma[1,], sigma[2,c(2,3)], sigma[3,3])
sigma
#rWishart(1,3,diag(0.1,3))
#means = c(0,0,0)
#epsilon = rmvnorm(1, means, sigma)
#beta: 1*18 vector, where beta_kj is the [6*(j-1)+(k+1)]th number.
#beta = rmvnorm(1, rep(0,21), diag(1,21))
beta = rep(0.005,21)
```

Density function.

```{r}
# for each yi
logdy = function(obs, beta, rho, sigma){
  x = c(1,obs[7:12])
  y = obs[1:3]
  mu = beta %*% x + rho*obs[1:3]
  dy = dmvnorm(obs[4:6], mean = mu, sigma = sigma)
  return(log(dy))
}

#traintest = train_data[c(1:100),]
#betatest = rep(0.008,21)
#apply(traintest, 1, logdy, beta.=betatest)

logdensity = function(data=train_data, beta.=beta, rho.=rho, sigma.=sigma){
  beta_m = matrix(beta.,3)
  sigma_m = matrix(c(sigma.[c(1:3)], sigma.[2], sigma.[c(4,5)], sigma.[c(3,5)], sigma.[6]), 3)
  logdy = apply(data, 1, logdy, beta=beta_m, rho=rho., sigma=sigma_m)
  logdens = sum(logdy) + log(dmvnorm(beta., rep(0,21), diag(1,21))) + log(dtruncnorm(rho.[1], a=0, b=1, mean = 0.5, sd = 0.2)) + log(dtruncnorm(rho.[2], a=0, b=1, mean = 0.5, sd = 0.2)) + log(dtruncnorm(rho.[3], a=0, b=1, mean = 0.5, sd = 0.2)) + log(MCMCpack::diwish(sigma_m, 3, diag(0.1,3))) 
  return(logdens)
}

#logdensity(train_data)
```

Sampling process.

```{r}
regularMHstep = function(startpars, niter = 1000, rhoa, betaa, sigmaa){
  beta_m = matrix(NA, niter, 21)
  rho_m = matrix(NA, niter, 3)
  sigma_m = matrix(NA, niter, 6)
  beta_m[1,] = startpars$beta
  rho_m[1,] = startpars$rho
  sigma_m[1,] = startpars$sigma
  for (i in 2:niter) {   # correlated issue
    #posbeta = beta_m[i-1,] + runif(21,-1,1)*beta_a*ifelse((runif(21) < 0.1),1,0)
    #posrho = rho_m[i-1,] + runif(3,-1,1)*rho_a*ifelse((runif(3) < 0.1),1,0)
    #possigma = sigma_m[i-1,] + runif(6,-1,1)*sigma_a*ifelse((runif(6) < 0.1),1,0)
    posbeta = beta_m[i-1,] + runif(21,-1,1)*beta_a
    posrho = rho_m[i-1,] + runif(3,-1,1)*rho_a
    possigma = sigma_m[i-1,] + runif(6,-1,1)*sigma_a
    possigma_m = matrix(c(possigma[c(1:3)], possigma[2], possigma[c(4,5)], possigma[c(3,5)], possigma[6]), 3)
    if (sum(ifelse(posrho<1, 0, 1))==0 & is.positive.definite(possigma_m)) {
      if (log(runif(1)) < logdensity(beta.=posbeta, rho.=posrho, sigma.=possigma) - logdensity(beta.=beta_m[i-1,], rho.=rho_m[i-1,], sigma.=sigma_m[i-1,])){
        beta_m[i,] = posbeta
        rho_m[i,] = posrho
        sigma_m[i,] = possigma
        }
      else{
        beta_m[i,] = beta_m[i-1,]
        rho_m[i,] = rho_m[i-1,]
        sigma_m[i,] = sigma_m[i-1,]
      }}
    else{
      beta_m[i,] = beta_m[i-1,]
      rho_m[i,] = rho_m[i-1,]
      sigma_m[i,] = sigma_m[i-1,]
      }
  }
  return(list(MHbeta = beta_m, MHrho = rho_m, MHsigma = sigma_m))
}
```

```{r}
compMHstep = function(startpars, niter = 1000, rhoa, betaa, sigmaa){
  beta_m = matrix(NA, niter, 21)
  rho_m = matrix(NA, niter, 3)
  sigma_m = matrix(NA, niter, 6)
  beta_m[1,] = startpars$beta
  rho_m[1,] = startpars$rho
  sigma_m[1,] = startpars$sigma
  for (i in 2:niter) {  
    posbeta = beta_m[i-1,]
    for (j in 1:21) {
      curbeta = posbeta
      posbeta[j] = posbeta[j] + runif(1,-1,1)*beta_a[j]
      if (log(runif(1)) >= logdensity(beta.=posbeta, rho.=rho_m[i-1,], sigma.=sigma_m[i-1,]) - logdensity(beta.=curbeta, rho.=rho_m[i-1,], sigma.=sigma_m[i-1,])){
        posbeta[j] = curbeta[j]
      }
      }
    beta_m[i,] = posbeta
    posrho = rho_m[i-1,]
    for (j in 1:3) {
      currho = posrho
      posrho[j] = posrho[j] + runif(1,-1,1)*rho_a[j]
      if (sum(ifelse(posrho<1, 0, 1))==0) {
        if (log(runif(1)) >= logdensity(beta.=beta_m[i,], rho.=posrho, sigma.=sigma_m[i-1,]) - logdensity(beta.=beta_m[i,], rho.=currho, sigma.=sigma_m[i-1,])){
          posrho[j] = rho_m[i-1,j]
        }
      }
      else{
        posrho[j] = rho_m[i-1,j]
      }
      }
    rho_m[i,] = posrho
    possigma = sigma_m[i-1,]
    for (j in 1:6) {
      cursigma = possigma
      possigma[j] = possigma[j] + runif(1,-1,1)*sigma_a[j]
      possigma_m = matrix(c(possigma[c(1:3)], possigma[2], possigma[c(4,5)], possigma[c(3,5)], possigma[6]), 3)
      if (is.positive.definite(possigma_m)) {
        if (log(runif(1)) >= logdensity(beta.=beta_m[i,], rho.=rho_m[i,], sigma.=possigma) - logdensity(beta.=beta_m[i,], rho.=rho_m[i,], sigma.=cursigma)){
          possigma[j] = sigma_m[i-1,j]
        }
      }
      else{
        possigma[j] = sigma_m[i-1,j]
      }
    }
    sigma_m[i,] = possigma
  }
  return(list(MHbeta = beta_m, MHrho = rho_m, MHsigma = sigma_m))
}
```

```{r}
# starting points of parameters
startpars = list(rho = rho, beta = beta, sigma = sigma)
rho_a = c(0.005,0.01,0.05)
sigma_a = rep(0.5, 6)
beta_a = c(rep(0.01, 3), rep(0.001, 6), rep(0.005, 6), 0.01, rep(0.005, 5))
```

```{r}
set.seed(123)
library(parallel)
nCores<-detectCores() # detect numbers of available cores 
cl = makeCluster(nCores)
MHresults = compMHstep(startpars, niter = 1000, rhoa = rho_a, betaa = beta_a, sigmaa = sigma_a)
stopCluster(cl)
```

```{r}
MHresults = regularMHstep(startpars, niter = 10, rhoa = rho_a, betaa = beta_a, sigmaa = sigma_a)
```


```{r}
uni_beta = rep(NA,21)
for (i in 1:21){
  uni_beta[i] = length(unique(MHresults$MHbeta[,i]))
}
uni_beta

uni_sigma = rep(NA,6) 
for (i in 1:6) {
  uni_sigma[i] = length(unique(MHresults$MHsigma[,i]))
}
uni_sigma

uni_rho = rep(NA,3)
for (i in 1:3) {
  uni_rho[i] = length(unique(MHresults$MHrho[,i]))
}
uni_rho
```

```{r}
niter = 100
beta_results = as.data.frame(MHresults$MHbeta) %>% 
  mutate(x = 1:niter) %>% 
  gather(key = beta, value = value, V1:V21) %>% 
  mutate(beta = str_replace(beta, "V", ""))
beta_plot = ggplot(beta_results, aes(x = x, y = value, color = beta)) +
  geom_line()
ggsave("beta_plot100.jpeg", beta_plot)
 
rho_results = as.data.frame(MHresults$MHrho) %>% 
  mutate(x = 1:niter) %>% 
  gather(key = rho, value = value, V1:V3) 
rho_plot = ggplot(rho_results, aes(x = x, y = value, color = rho)) +
  geom_line()
ggsave("rho_plot100.jpeg", rho_plot)

sigma_results = as.data.frame(MHresults$MHsigma) %>% 
  mutate(x = 1:niter) %>% 
  gather(key = sigma, value = value, V1:V6) 
sigma_plot = ggplot(sigma_results, aes(x = x, y = value, color = sigma)) +
  geom_line()
ggsave("sigma_plot100.jpeg", sigma_plot)
```


